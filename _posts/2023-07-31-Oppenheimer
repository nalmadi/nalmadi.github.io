---
layout: post
title: "What Oppenheimer Tells Us about AI"
author: "Naser"
categories: 
tags:
image: Oppenheimer.jpeg
---
Cillian Murphy as J. Robert Oppenheimer in 'Oppenheimer' COURTESY OF UNIVERSAL PICTURES

  

It was Stephen Fry who said: 'A true thing, poorly expressed, is a lie.'  With Oppenheimer, we are presented with a true story masterfully portrayed through the lens of Christopher Nolan. The story of Dr. Robert Oppenheimer, the American theoretical physicist, and director of the Manhattan Project's Los Alamos Laboratory during World War II, is a masterclass in storytelling and film.


However, the reason I am writing about Oppenheimer today goes beyond the film's excellent form, after all "art is not supposed to look nice, it is supposed to make you feel something." Beyond the cinematic brilliance, the movie raises a profound discussion of ethics and the human tendency to suspend moral judgment in the face of great benefit or great fear.  Perhaps it was my narcissistic perspective as a computer science professor to draw parallels between the rationalizations made by Robert Oppenheimer and those prevalent in the AI industry today.


Despite the clear moral dilemma that Oppenheimer expressed throughout his life before and after creating the first nuclear weapon, the leading theme in this movie was the idea that Oppenheimer was lured by a great good (ending WWII) into committing a great evil (creating nuclear weapons). This leads me to wonder if we are making the same mistake with AI today.


More specifically, the underlying rationalization in the race to weaponize the atom with the mindset of "if we don't do it, someone else will" is all too familiar in our current discussion of AI. One example is Sam Altman the CEO of OpenAI who stated "A.I. poses a risk of extinction on par with pandemics and nuclear warfare," only weeks after releasing ChatGPT, which poses an immediate threat to millions of jobs today. The temptation of great benefits and claiming the title of being first is often too blinding from thinking about how AI will affect humanity and our world.


Even the most responsible members of the AI community agree that frameworks and regulations should be put in place to control the ethical use of AI, yet most of these frameworks are not established or simply not enforced in practice. This makes me wonder if we are being lured into a naive optimism, believing we can make AI ethical before irreparable damage is done, much like the naive optimism Oppenheimer had believing nuclear weapons will end all wars. The process of creating larger and more powerful AI models without considering ethical implications is strikingly relevant in this movie.  Yet the most profound idea I take from Oppenheimer is that conducting science without understanding its impact on the world is immoral, even if the short-term gains seem substantial. This idea underscores the necessity of incorporating the humanities into great engineering endeavors.


To end on a more hopeful note (which is unusual for me), if we ever make ethical progress in AI in the future, it will be through the hands of engineers who are trained in philosophy, ethics, linguistics, art, and the humanities in general along with their training in natural science.
